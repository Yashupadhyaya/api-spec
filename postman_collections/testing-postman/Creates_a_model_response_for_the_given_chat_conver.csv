model,messages,frequency_penalty,top_logprobs,max_tokens,n,presence_penalty,type,seed,stop,temperature,top_p,tools,tool_choice,user,function_call,functions,statusCode,scenario
gpt-3.5-turbo,2,0,5,32,1,0,text,9223372036854776000,stop,1,1,3,tool_choice,user-1234,function_call,5,200,OK
gpt-3.5-turbo,1,-2,0,64,1,2,json_object,-9223372036854776000,stop,2,1,4,tool_choice,user-1234,function_call,4,200,OK
gpt-3.5-turbo,2,2,5,128,1,-2,text,9223372036854776000,stop,0,1,5,tool_choice,user-1234,function_call,3,200,OK
gpt-3.5-turbo,1,0,0,32,1,0,json_object,-9223372036854776000,stop,1,1,2,tool_choice,user-1234,function_call,2,200,OK
gpt-3.5-turbo,2,-2,5,64,1,2,text,9223372036854776000,stop,2,1,1,tool_choice,user-1234,function_call,1,200,OK