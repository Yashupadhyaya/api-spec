model,messages,frequency_penalty,top_logprobs,max_tokens,n,presence_penalty,type,seed,stop,temperature,top_p,tools,tool_choice,user,function_call,functions,statusCode,scenario
gpt-3.5-turbo,1,0,5,100,1,0,text,9223372036854776000,null,1,1,[],tool_1,user-1234,function_1,[],200,OK
gpt-3.5-turbo,2,-1,4,200,2,-1,json_object,-9223372036854776000,null,2,0.5,[],tool_2,user-1235,function_2,[],201,OK
gpt-3.5-turbo,3,1,3,300,3,0.5,text,0,null,1.5,0.25,[],tool_3,user-1236,function_3,[],202,OK
gpt-3.5-turbo,1,-2,2,400,4,1,json_object,4609123456789134,null,0.75,0.75,[],tool_4,user-1237,function_4,[],203,OK
gpt-3.5-turbo,2,2,1,500,5,-2,text,-4609123456789134,null,0.25,0.125,[],tool_5,user-1238,function_5,[],204,OK
gpt-3.5-turbo,1,-2,5,400,2,2,json_object,721474836400,address,null,0.3,0.7,[],tool_6,user-1239,function_6,[],120,Not OK
gpt-3.5-turbo,3,-1,4,300,3,-1,text,-721474836400,stop,1.6,0.8,[],tool_7,user-1240,function_7,[],400,Not OK
