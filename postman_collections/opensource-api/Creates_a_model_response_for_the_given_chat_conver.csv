model,messages,frequency_penalty,top_logprobs,max_tokens,n,presence_penalty,type,seed,stop,temperature,top_p,tools,tool_choice,user,function_call,functions,statusCode,scenario
gpt-3.5-turbo,1,0,5,100,1,0,json_object,9223372036854776000,,1,1,[],{},user-1234,{},[],200,OK
gpt-3.5-turbo,1,-1,4,200,2,0,text,9223372036854776000,,0.5,1,[],{},user-1234,{},[],200,OK
gpt-3.5-turbo,2,2,3,300,1,-1,json_object,-9223372036854776000,,1.5,1,[],{},user-1234,{},[],201,OK
gpt-3.5-turbo,3,-2,2,400,3,1,text,-9223372036854776000,,2,1,[],{},user-1234,{},[],202,OK
gpt-3.5-turbo,1,0,1,500,1,0,json_object,0,,1,1,[],{},user-1234,{},[],203,OK
gpt-3.5-turbo,1,1,0,600,4,-1,text,0,,0.5,1,[],{},user-1234,{},[],204,OK
gpt-3.5-turbo,2,-1,5,700,1,1,json_object,9223372036854776000,,1.5,1,[],{},user-1234,{},[],205,OK
gpt-3.5-turbo,2,1,4,800,2,-1,text,-9223372036854776000,,2,1,[],{},user-1234,{},[],206,OK